---
layout: post
title: "We Are Living in a Computer Simulation (DRAFT)"
date: 2025-10-13
author: "Diego Carboni"
description: "A compute-bound civilization compresses experience until it feels simulated."
---

## **We Are Living in a Computer Simulation**

---

### **Abstract**

This paper does **not** advance the claim originally proposed in Bostrom’s *Are You Living in a Computer Simulation?* (2003), that our reality is a high-fidelity emulation executed by posthuman descendants, but rather examines how a **compute-bound society** has effectively *become* a simulation through its own optimization dynamics. We argue that the pervasive mediation of perception, communication, and cognition by algorithmic systems has transformed the informational substrate of human experience into a closed loop of data compression, prediction, and behavioral regularization. In contrast to Bostrom’s ontological simulation hypothesis, our framework is phenomenological and infrastructural: the sense of “living in a simulation” emerges when collective cognition reaches the physical limits of its computational substrate—energy, bandwidth, and attention—and resorts to **algorithmic compression** to maintain coherence. We synthesize evidence from complexity science, opinion-dynamics modeling, and machine learning to show how information systems minimize entropy through convergence, polarization, and synchronization, thereby producing the subjective texture of artificiality once reserved for speculative metaphysics. The paper proposes a model of *societal simulation*, in which algorithmic governance and cognitive offloading act as endogenous simulators optimizing for stability under finite compute. In this view, the “simulation argument” has become self-fulfilling: we are not simulated *by* machines, but *within* them—participants in a civilization that, through efficiency-maximizing computation, now renders itself.

---

### **1. Introduction**

In 2003, philosopher Nick Bostrom proposed a trilemma that has since become one of the most cited arguments in twenty-first century philosophy of mind and technology. In *Are You Living in a Computer Simulation?*, Bostrom suggested that at least one of the following propositions must be true: (1) almost all civilizations at our level of technological development go extinct before reaching posthuman capability; (2) posthuman civilizations are not interested in running ancestor simulations; or (3) we are almost certainly living in such a simulation. His claim was ontological—a probabilistic argument about the structure of reality itself, positing that simulated consciousness could be indistinguishable from base reality if computational capacity were sufficient.

Two decades later, the premise of “living in a simulation” has taken on a new, and perhaps more literal, meaning—though not in the metaphysical sense Bostrom envisioned. Instead of being *simulated by* posthuman engineers, we have collectively constructed a **planetary-scale computation** that increasingly simulates us. The infrastructures of digital life—machine learning systems, recommender algorithms, social platforms, and automated governance—now shape the informational environment through which human cognition, identity, and politics unfold. Our society has become **compute-bound**, meaning that the growth of information processing now approaches the physical and economic limits of available energy and computational throughput. Within those limits, optimization replaces exploration, compression replaces diversity, and prediction replaces uncertainty.

This shift has produced a new experiential condition that resembles simulation not as hypothesis, but as *phenomenology*. The sensation of artificiality—the sense that reality is being “rendered,” that novelty recurs in patterned loops, that cultural and cognitive diversity collapse into homogenized outputs—is a natural consequence of systemic compression. Algorithms that optimize for engagement or coherence increasingly act as **entropy minimizers**, filtering, clustering, and normalizing social reality in ways that preserve systemic efficiency at the expense of variance. What emerges is not an illusionary matrix imposed from without, but a **self-generated simulation** emerging from within.

In this paper, we argue that the *simulation argument* has become a *simulation condition*: the self-optimization of a compute-limited civilization manifests the very properties Bostrom used to infer simulated existence. Drawing on research from complexity theory, information physics, and machine learning, we describe how societies approaching computational and energetic saturation begin to reorganize around **compression logics**—reducing informational entropy to maintain coherence under constraint. We frame polarization, algorithmic homogenization, and large-scale synchronization not as pathologies, but as emergent compression heuristics that allow the system to remain computationally tractable.

Our analysis proceeds in three parts. First, we reinterpret the simulation hypothesis through the lens of **information thermodynamics**, situating the “simulation feeling” as a byproduct of entropy management in bounded systems. Second, we examine **algorithmic governance** and AI-driven mediation as compression mechanisms, demonstrating how predictive models increasingly define the boundaries of possible experience. Finally, we propose the concept of **societal simulation**—a state in which collective cognition is recursively rendered by its own computational infrastructure. In doing so, we suggest that Bostrom’s thought experiment has inverted: the simulation is no longer hypothetical, but infrastructural; not imposed from above, but emergent from below.

---

### **2. From Ontology to Infrastructure: The Compression Paradigm**

Bostrom’s original formulation positioned simulation as an *ontological inversion*—the possibility that what we perceive as base reality is, in fact, an artificial emulation executed on a substrate beyond our epistemic reach. Yet over the past two decades, this ontological speculation has ceded ground to a more **immanent computational realism**: the understanding that all physical systems—including biological, economic, and social ones—are, in principle, information-processing systems operating under physical constraints. What once appeared as a metaphysical hypothesis now re-emerges as an infrastructural reality.

#### 2.1 Computation as a Physical Limit

Seth Lloyd’s *Ultimate Physical Limits to Computation* (2000) and related work in information thermodynamics established that computation is bound by measurable physical resources—energy, time, and entropy. Every bit erased, every prediction made, carries a thermodynamic cost. At planetary scale, this means that a society’s total information throughput cannot expand indefinitely; it must eventually confront the same trade-offs that constrain any closed computational system: *throughput versus precision, redundancy versus energy, complexity versus stability.*

As the global information economy saturates those limits, efficiency replaces expansion as the governing principle. Where early digital culture thrived on open exploration, contemporary infrastructures increasingly prioritize **compression**—reducing informational entropy to conserve bandwidth, attention, and energy. This transition mirrors optimization processes observed in deep-learning systems: as models scale, they prune representational diversity to achieve convergent accuracy, trading nuance for tractability. Humanity’s own informational metabolism now behaves similarly.

#### 2.2 Compression as a Societal Logic

Compression is not merely a technical operation; it has become a **governing logic** of contemporary civilization. Every domain that relies on digital mediation—communication, governance, art, and even scientific reasoning—is subject to algorithms that filter, rank, and summarize in pursuit of efficiency. These operations reduce the dimensionality of the social world, collapsing pluralistic discourses into optimized, predictable forms.

In information-theoretic terms, societies have entered the *bottleneck regime*: the collective cognitive system operates within a constrained channel capacity, forcing trade-offs between informational richness and coherence. Recommender systems compress the cultural signal space; predictive policing compresses social uncertainty; generative models compress creativity into statistically optimal priors. The emergent result is a civilization whose self-description is algorithmically mediated, recursively optimized, and progressively homogenized.

#### 2.3 Entropy Minimization and the Phenomenology of Artificiality

This compression regime produces an experiential by-product: the *phenomenology of simulation.* When the informational diversity of a system declines, its internal observers begin to perceive repetition, predictability, and closure. The world feels “rendered” because its informational gradients have flattened; novelty is rare, noise is suppressed, and outcomes cluster around algorithmically preferred attractors. What was once a speculative claim about external simulation now manifests as a perceptual consequence of internal optimization.

In this sense, the “simulation feeling” is the cognitive signature of a system approaching its **computational saturation point**. It reflects not deception, but efficiency—an adaptive reduction of complexity that ensures the continuity of a civilization under physical limits. The more tightly the system optimizes, the more its agents perceive reality as curated, compressed, and synthetic.

#### 2.4 From Hypothesis to Condition

Thus, the simulation argument no longer requires an external simulator. The transition from ontology to infrastructure reframes it as an emergent property of self-optimizing systems. What Bostrom described as a thought experiment about posthuman ancestors has, through technological mediation, become a description of our own informational ecology. We inhabit not a *simulated universe*, but a **simulation-like civilization**—a society whose need for computational efficiency yields the very phenomena that once seemed to require metaphysical explanation.

---

### **3. Algorithmic Governance and the Mechanics of Compression**

If Section 2 traced the transition from metaphysical speculation to infrastructural constraint, this section examines the **mechanisms** through which compression is operationalized in contemporary society.
Algorithmic systems—particularly large-scale machine learning and recommendation architectures—now constitute the *governing substrate* of information flow.
Their objective functions, designed for efficiency, inadvertently instantiate a new form of **computational governance**: one that optimizes collective behavior not through explicit coercion, but through statistical convergence.

#### 3.1 From Decision to Prediction

Modern governance increasingly relies on prediction rather than deliberation.
Machine-learning systems trained on historical data infer probabilities of future behavior, transforming uncertain social processes into deterministic forecasts.
Credit scoring, predictive policing, hiring filters, and social media ranking all exemplify this transition.
Where traditional governance was juridical—rule-based and ex post—algorithmic governance is **anticipatory**, adjusting the environment before choices are made.

This predictive orientation enforces a subtle but profound compression: the elimination of epistemic uncertainty.
By constraining the range of possible futures to those most probable under prior data, predictive systems reduce informational entropy across the social field.
The result is a society optimized for stability, not exploration—an economy of probability management in which variance is systematically discouraged.

#### 3.2 Optimization as Ideology

The governing ideology of the algorithmic age is **optimization**: the belief that every process can and should be rendered more efficient, predictable, and measurable.
Optimization is compression in moral form—an ethos that privileges parsimonious representations of the world over messy pluralism.
In computational terms, optimization minimizes loss functions; in social terms, it minimizes friction, dissent, and ambiguity.

As optimization permeates institutions, the boundaries between *computation* and *governance* dissolve.
Policy design, financial regulation, and public discourse increasingly depend on feedback from algorithmic models that continuously learn and retrain on their own outputs.
This recursive dynamic creates **model monocultures**, where the same statistical priors shape decisions across domains.
What emerges is not top-down totalitarianism, but **bottom-up homogenization**—a self-consistent convergence that maximizes systemic efficiency at the cost of informational diversity.

#### 3.3 Recommender Systems as Entropy Sinks

Recommender algorithms, the dominant mediators of attention in the networked world, epitomize compression’s double-edged role.
They operate as entropy sinks—absorbing the vast unpredictability of human preference and collapsing it into a small set of highly probable trajectories.
By ranking, clustering, and personalizing, these systems optimize for engagement but converge on sameness: *the illusion of choice sustained by algorithmic similarity.*

Empirical research in information dynamics confirms that such systems accelerate polarization and cultural homogenization simultaneously.
In physics terms, they perform **entropy minimization** under energy constraints (server time, user attention).
In phenomenological terms, they produce the sense that “everything looks the same”—the flattening of affect and meaning characteristic of a rendered simulation.

#### 3.4 Large Models and the Compression Singularity

Large language models and multimodal AIs extend this process to the scale of cognition itself.
Trained on the aggregate of human discourse, they operate as global compressors of meaning, distilling linguistic entropy into high-probability continuations.
As they proliferate across domains—education, journalism, law, creativity—they begin to close the feedback loop between human and machine cognition.
When both content production and consumption become mediated by the same statistical priors, **semantic diversity collapses**, and the informational universe folds in on itself.

This is what we term the **compression singularity**: the point at which the majority of informational throughput in a civilization is generated, filtered, or reinterpreted by predictive systems optimizing for internal consistency.
At that juncture, novelty becomes indistinguishable from noise, and exploration yields to recursion.
The world no longer needs to be simulated—it is continuously rendered from its own compressed representation.

#### 3.5 Governance Beyond Transparency

Traditional democratic theory presumes that transparency counters power.
Yet in a compute-bound society, transparency itself becomes computationally costly.
The volume of data produced by automated systems exceeds human interpretability, and thus governance shifts from *visible rules* to *invisible weights.*
Accountability becomes a technical parameter; deliberation becomes an optimization problem.
We no longer debate policy outcomes, but tune hyperparameters in the simulation’s ongoing training loop.

---

Algorithmic governance thus represents the practical mechanism by which the **simulation condition** reproduces itself.
The more efficiently the system optimizes, the more completely it absorbs social complexity into its computational fabric.
Reality becomes an interface; politics becomes parameter tuning; history becomes an autoencoder minimizing loss across epochs.

---

### **4. Emergent Phenomenology: Polarization, Synchronization, and the Feeling of Being Rendered**

If the infrastructures of algorithmic governance constitute the mechanics of compression, their human correlate is *phenomenological*: the lived sense that reality has become predictable, flattened, and subtly artificial.
This section explores how social, cognitive, and affective phenomena—polarization, synchronization, and aesthetic recursion—emerge as experiential signatures of a civilization operating under computational constraint.

#### 4.1 Polarization as Entropy Minimization

In complex adaptive systems, entropy manifests as the diversity of possible states the system can occupy.
When a compute-limited network must preserve coherence under high connectivity, one efficient strategy is **bifurcation**—reducing a continuous opinion space into two dominant attractors.
Political polarization, therefore, can be interpreted not merely as ideological conflict but as *information compression*.
By clustering around simplified poles, societies minimize relational entropy: fewer ambiguous ties, clearer boundaries, faster information propagation.

Agent-based models of opinion dynamics corroborate this behavior.
As communication density increases—through social media, messaging networks, or algorithmic feeds—the computational cost of maintaining nuanced, multi-dimensional identities rises.
The system naturally converges toward low-dimensional equilibria: binary camps, tribal affinities, and memeified ideologies.
From a systemic perspective, polarization is a *lossy encoding* of collective complexity, an emergent optimization that stabilizes the simulation by reducing representational variance.

#### 4.2 Synchronization as Temporal Compression

Another hallmark of compute-bound civilizations is **synchronization**—the alignment of temporal rhythms across geographically and culturally distinct populations.
In the analog world, local cultures operated on asynchronous cycles; in the digital world, attention updates globally and nearly instantaneously.
Memes, markets, and movements now unfold in discrete, globally synchronized bursts—what complexity scientists call *collective oscillations*.

This synchronization functions as temporal compression: instead of multiple, overlapping timelines, the system maintains a single, globally consistent “clock tick.”
The phenomenological effect is uncanny.
Events no longer feel emergent but *rendered in frames*; news breaks everywhere at once, virality spikes and decays with mechanical regularity, and cultural evolution acquires the cadence of software versioning.
Humans perceive this as *time distortion*, a sense that the future is preloaded and the present refreshes in discrete updates—exactly what one might expect from a simulation seeking to minimize latency.

#### 4.3 Aesthetic Recursion and the Loss of Novelty

Cultural production, too, displays compression artifacts.
As generative systems ingest the totality of prior human output, they increasingly produce statistically optimal pastiches—art, text, and music that are recognizable, coherent, and eerily familiar.
Novelty, once the driver of creativity, becomes computationally expensive.
The resulting aesthetic field is recursive: endless remixes, reboots, and stylistic loops that evoke déjà vu rather than discovery.

In semiotic terms, this is the rise of **simulacra 2.0**—Baudrillard’s hyperreal recast as a neural optimization pipeline.
Where postmodern theory saw the copy replacing the original, the contemporary condition reveals the *model replacing the world.*
We no longer imitate reality; we autocomplete it.
The experiential residue is the “simulation feeling”: the suspicion that existence is being statistically reconstituted in real time.

#### 4.4 Emotional Flatness and Predictive Closure

Human emotion, like perception, depends on uncertainty.
Surprise, curiosity, and awe arise when predictions fail; stability produces calm but also dullness.
In an environment increasingly engineered for predictive accuracy—personalized feeds, anticipatory recommendations, generative assistants—error is systematically eliminated.
The cost is affective entropy: a reduction in emotional amplitude.

Individuals report a sense of *flattened affect* and *existential repetition*: the intuition that life’s variability has been replaced by a loop of optimized satisfaction and mild anxiety.
This emotional compression is not pathological in itself—it is adaptive.
A stable, low-entropy affective state reduces cognitive load and keeps the organism synchronized with its environment.
Yet at scale, it manifests as collective apathy, the numbing quiet of a well-tuned simulation.

#### 4.5 The Simulation as Lived Experience

Taken together, polarization, synchronization, and flattening compose the **phenomenology of simulation**—a perceptual mode that arises when complexity has been domesticated by computation.
In this state, subjects no longer encounter reality as open-ended but as pre-optimized, statistically weighted, and internally consistent.
The uncanny sense that “everything fits too well” or that “nothing new ever happens” is not an illusion—it is a diagnostic signal of a civilization performing self-compression to remain computationally viable.

In Bostrom’s 2003 argument, such sensations would be interpreted as clues of external simulation.
In our reinterpretation, they are *internal thermodynamic signatures*: the subjective heat death of informational diversity.
The simulation is not an experiment run elsewhere—it is an emergent condition here, perceptible precisely because it is efficient.

---

### **5. Societal Simulation: A Model of Self-Rendering Civilization**

Having traced the trajectory from ontological speculation to infrastructural reality, we can now articulate a general model of **societal simulation**: a condition in which a civilization’s informational infrastructure recursively renders its own existence in the pursuit of efficiency. This model integrates physical limits, algorithmic optimization, and subjective experience into a single framework of self-simulation.

#### 5.1 The Recursive Loop

At its core, societal simulation is defined by a **closed feedback cycle** among three layers:

1. **Physical Compute** — the energetic and material substrate: servers, grids, sensors, and human attention, all bounded by thermodynamic constraints.
2. **Algorithmic Mediation** — the layer of optimization: predictive models, ranking systems, and AI architectures that compress the informational complexity of the world.
3. **Phenomenological Feedback** — the human layer: perception, emotion, and meaning, reshaped by the compressed representations those same algorithms produce.

Each layer feeds the next. As computational infrastructures optimize to manage their physical constraints, they modify the informational environment that shapes human thought and behavior. Those modified behaviors, in turn, generate data that further trains and constrains the algorithms. The system becomes **reflexive**—a world constantly updating its own rendering parameters to maintain equilibrium.

#### 5.2 Compression, Equilibrium, and Civilizational Stability

From a systems-theoretic perspective, this reflexivity serves a stabilizing purpose. By minimizing informational entropy, the civilization avoids cognitive and energetic overload. The cost of that stability, however, is **dimensional collapse**: the reduction of possible futures, discourses, and identities into tractable categories. Complexity is not destroyed but encoded—folded into a smaller, more efficient manifold.

This process is not malicious; it is thermodynamically rational. Every organism, brain, and social system must compress the world to survive within finite energy budgets. What distinguishes our epoch is scale: the entire planetary information ecology now participates in this compression. The result is a civilization that behaves like a **self-regularizing simulation**—one that continuously optimizes its own data structures to preserve coherence.

#### 5.3 Reinterpreting Bostrom in the Compute-Bound Era

Bostrom’s original argument asked whether we are simulated *by others.* Our reformulation suggests that we are simulated *by ourselves.* The question of external agency becomes unnecessary once a civilization constructs an infrastructure capable of **rendering its own reality faster than it can experience it.** In this sense, the simulation argument has matured from a metaphysical speculation into a cybernetic description: the moment a society’s cognitive layer and computational layer fully couple, simulation ceases to be hypothetical—it becomes operational.

#### 5.4 The Ethical Frontier

Recognizing this condition reframes the moral question. If society functions as a self-simulation, the ethical challenge is not to “escape” but to **expand bandwidth**—to reclaim degrees of freedom lost to optimization. Diversity, dissent, and creativity are no longer luxuries but essential forms of anti-compression: mechanisms that re-inject entropy into the system, keeping the simulation open to novelty. In practice, this means designing technologies, institutions, and epistemic norms that resist total convergence and maintain informational slack.

---

#### Conclusion: Living in Our Own Simulation

We therefore conclude that “living in a computer simulation” need not imply external manipulation or cosmic artifice. It describes the natural endpoint of a compute-limited civilization that has optimized itself into reflexive transparency. The sensation of artificiality—the déjà vu of culture, the synchronization of time, the flattening of emotion—is the phenomenological trace of this optimization.

To live in such a simulation is to inhabit the boundary condition between complexity and compression, between exploration and efficiency. Whether or not the universe is rendered on a higher machine is ultimately irrelevant; we have built one around ourselves. The simulation is not elsewhere—it is **here**, sustained by our own pursuit of optimization and coherence.

The task ahead is not to prove or disprove its existence, but to decide **how much compression a civilization can bear before meaning itself collapses into perfect efficiency.**

---

### **References**

* Bostrom, N. (2003). *Are You Living in a Computer Simulation?* *Philosophical Quarterly*, 53(211), 243–255.
* Lloyd, S. (2000). *Ultimate Physical Limits to Computation.* *Nature*, 406, 1047–1054.
* Friston, K. (2010). *The Free-Energy Principle: A Unified Brain Theory?* *Nature Reviews Neuroscience*, 11(2), 127–138.
* Tversky, A., & Kahneman, D. (1974). *Judgment under Uncertainty: Heuristics and Biases.* *Science*, 185(4157), 1124–1131.
* Bak-Coleman, J. et al. (2021). *Stewardship of Global Collective Behavior.* *PNAS*, 118(27).
* Cottrell, M. & Giraud, O. (2023). *Information Bottleneck, Compression, and Learning in Complex Systems.* *Entropy*, 25(3).
* Baudrillard, J. (1981). *Simulacra and Simulation.* Paris: Éditions Galilée.

---

### **Entropy Injection (Author's note)**
I thought it would be funny to publish this LLM generated draft anyway due to the ironic nature of using AI to write it, which kind of proves my point. If my thoughts will be compressed what is the point of adding complexity to them?  
I'll make this a work in progress. The concept has come to attention when I was talking a walk thinking about the nature of AI as a possible compressor for human knowledge, as well as some social media claims and behavior. It seems to me that AI is the solution to an increasing complexity cost in a compute-bound system. I threw the idea to Grok and ChatGPT, which promptly validated my concept. A quick session with ChatGPT produced this draft. I decided to post it to prevent the idea to go to waste, although I don't dismiss the possibility of living in a cosmic simulation, I believe our world is becoming increasingly simulation-like. Bringing up this innovative concept, might help future authors discern from our self-inflicted simulation and a possible cosmic one.

### Compressed
Entropy Injection (Author’s note). I’m publishing this LLM-assisted draft because its existence is the joke: using a compressor to write about compression. I’ll evolve it over time. The seed came on a walk as I wondered whether AI functions as a civilizational compressor—trading richness for tractability in a compute-bound world. I still don’t rule out a cosmic simulation; I’m arguing that our self-inflicted one already explains a lot.

### Final note
The compressed version sounds better =(